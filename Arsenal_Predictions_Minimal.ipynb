{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modélisation des Résultats d'Arsenal en Premier League\n",
        "\n",
        "Ce notebook présente un workflow data science complet et reproductible:\n",
        "- Chargement des données scrappées (Understat, FBref)\n",
        "- Préparation des données et Feature Engineering\n",
        "- Entraînement de modèles (Random Forest, XGBoost)\n",
        "- Évaluation et interprétation (métriques, courbes ROC, learning curves, importances)\n",
        "- Visualisations claires pour communication à des parties prenantes\n",
        "\n",
        "Objectif: prédire l’issue d’un match (défaite, nul, victoire) et expliquer les facteurs clés associés aux performances d’Arsenal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports minimaux\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import xgboost as xgb\n",
        "\n",
        "# Le notebook s'exécute depuis son dossier (notebooks_min)\n",
        "# Les CSV ont été copiés dans notebooks_min/data → utiliser le chemin relatif \"data\"\n",
        "DATA_DIR = Path('data')\n",
        "if not (DATA_DIR.exists() and any(DATA_DIR.glob('*.csv'))):\n",
        "    # Fallback si exécuté depuis la racine du repo\n",
        "    DATA_DIR = Path('notebooks_min/data')\n",
        "\n",
        "print('Dossier données utilisé:', DATA_DIR.resolve())\n",
        "print('Fichiers disponibles:', list(DATA_DIR.glob('*.csv')))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline complet: chargement → préparation → features → split → entraînement\n",
        "# 1) Chargement CSV\n",
        "understat = pd.read_csv(DATA_DIR / 'understat_arsenal_matches.csv')\n",
        "fbref_team = pd.read_csv(DATA_DIR / 'fbref_arsenal_team_stats.csv')\n",
        "fbref_match = pd.read_csv(DATA_DIR / 'fbref_arsenal_match_stats.csv')\n",
        "\n",
        "# 2) Normalisation des colonnes et clés de jointure\n",
        "understat.columns = [c.lower() for c in understat.columns]\n",
        "fbref_team.columns = [c.lower() for c in fbref_team.columns]\n",
        "fbref_match.columns = [c.lower() for c in fbref_match.columns]\n",
        "\n",
        "# Harmoniser date\n",
        "for df in [understat, fbref_match]:\n",
        "    if 'date' not in df.columns:\n",
        "        for alt in ['match_date', 'game_date']:\n",
        "            if alt in df.columns:\n",
        "                df.rename(columns={alt: 'date'}, inplace=True)\n",
        "                break\n",
        "\n",
        "# Harmoniser opponent\n",
        "if 'opponent' not in understat.columns:\n",
        "    for alt in ['opponent_team', 'against', 'rival']:\n",
        "        if alt in understat.columns:\n",
        "            understat.rename(columns={alt: 'opponent'}, inplace=True)\n",
        "            break\n",
        "if 'opponent' not in fbref_match.columns:\n",
        "    for alt in ['opponent_team', 'against', 'rival']:\n",
        "        if alt in fbref_match.columns:\n",
        "            fbref_match.rename(columns={alt: 'opponent'}, inplace=True)\n",
        "            break\n",
        "\n",
        "# is_home\n",
        "if 'is_home' not in understat.columns and 'home_away' in understat.columns:\n",
        "    understat['is_home'] = understat['home_away'].astype(str).str.upper().map({'H': 1, 'A': 0}).fillna(0).astype(int)\n",
        "\n",
        "# Clés de merge\n",
        "for df in [understat, fbref_match]:\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "        df['date_key'] = df['date'].dt.strftime('%Y-%m-%d')\n",
        "    else:\n",
        "        df['date_key'] = np.nan\n",
        "    if 'opponent' in df.columns:\n",
        "        df['opponent_key'] = df['opponent'].astype(str).str.strip().str.lower()\n",
        "    else:\n",
        "        df['opponent_key'] = np.nan\n",
        "\n",
        "u_sel = understat.copy()\n",
        "fm_sel = fbref_match.copy()\n",
        "\n",
        "for col, default in [\n",
        "    ('goals', np.nan), ('goals_conceded', np.nan), ('xg', np.nan), ('xg_conceded', np.nan),\n",
        "    ('shots', np.nan), ('shots_on_target', np.nan), ('possession', np.nan)\n",
        "]:\n",
        "    if col not in u_sel.columns: u_sel[col] = default\n",
        "    if col not in fm_sel.columns: fm_sel[col] = default\n",
        "\n",
        "# Merge\n",
        "u_sel['date_key'] = u_sel['date_key'].astype(str)\n",
        "fm_sel['date_key'] = fm_sel['date_key'].astype(str)\n",
        "u_sel['opponent_key'] = u_sel['opponent_key'].astype(str)\n",
        "fm_sel['opponent_key'] = fm_sel['opponent_key'].astype(str)\n",
        "\n",
        "merged = pd.merge(\n",
        "    u_sel,\n",
        "    fm_sel[[c for c in fm_sel.columns if c not in ['goals', 'goals_conceded', 'xg', 'xg_conceded']]],\n",
        "    on=['date_key', 'opponent_key'], how='inner', suffixes=('', '_fb')\n",
        ")\n",
        "if merged.empty:\n",
        "    merged = u_sel.copy()\n",
        "\n",
        "# 3) Cible et features\n",
        "if 'goals' in merged.columns and 'goals_conceded' in merged.columns:\n",
        "    merged['result'] = np.where(merged['goals'] > merged['goals_conceded'], 'W',\n",
        "                         np.where(merged['goals'] == merged['goals_conceded'], 'D', 'L'))\n",
        "else:\n",
        "    merged['result'] = 'D'\n",
        "points_map = {'W': 3, 'D': 1, 'L': 0}\n",
        "merged['points'] = merged['result'].map(points_map).fillna(1).astype(int)\n",
        "merged['goal_difference'] = merged.get('goals', 0) - merged.get('goals_conceded', 0)\n",
        "merged['xg_difference'] = merged.get('xg', 0) - merged.get('xg_conceded', 0)\n",
        "if 'date' in merged.columns:\n",
        "    merged = merged.sort_values('date')\n",
        "merged['points_rolling_5'] = merged['points'].rolling(window=5, min_periods=1).mean()\n",
        "if 'is_home' not in merged.columns:\n",
        "    merged['is_home'] = 1\n",
        "\n",
        "# 4) Jeu de données d'entraînement\n",
        "tmp = merged.copy()\n",
        "tmp['result_encoded'] = tmp.get('result', pd.Series(['D']*len(tmp))).map({'L':0, 'D':1, 'W':2})\n",
        "X = tmp.select_dtypes(include=[np.number]).drop(columns=['points'], errors='ignore')\n",
        "y = tmp['points']\n",
        "\n",
        "# 5) Split et entraînement\n",
        "X = X.fillna(0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y if y.nunique()>1 else None\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=12, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "y_train_xgb = y_train.replace({3:2})\n",
        "y_test_xgb = y_test.replace({3:2})\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=300, learning_rate=0.1, max_depth=6, subsample=0.9, colsample_bytree=0.9,\n",
        "    random_state=42, reg_lambda=1.0\n",
        ")\n",
        "xgb_model.fit(X_train, y_train_xgb)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "print('Taille merged:', merged.shape)\n",
        "print('Accuracy RF:', round(accuracy_score(y_test, y_pred_rf), 3))\n",
        "print('Accuracy XGB:', round(accuracy_score(y_test_xgb, y_pred_xgb), 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Données et hypothèses\n",
        "- Understat: xG, buts, lieu du match, adversaire, date.\n",
        "- FBref (match-by-match): possession, tirs, passes, précision.\n",
        "- Alignement par `date` + `opponent` (fallback si alignement impossible).\n",
        "\n",
        "Hypothèses de modélisation:\n",
        "- Cible: points (0,1,3) dérivés du score.\n",
        "- Modèles: RandomForestClassifier, XGBClassifier.\n",
        "- Validation: split train/test + cross-validation stratifiée.\n",
        "- Indicateurs: accuracy, macro-F1, matrice de confusion, ROC multi-classes.\n",
        "- Interprétation: importances globales + partial dependence plots (si pertinent).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement brut des données\n",
        "understat = pd.read_csv(DATA_DIR / 'understat_arsenal_matches.csv')\n",
        "fbref_team = pd.read_csv(DATA_DIR / 'fbref_arsenal_team_stats.csv')\n",
        "fbref_match = pd.read_csv(DATA_DIR / 'fbref_arsenal_match_stats.csv')\n",
        "\n",
        "print(understat.head(2))\n",
        "print(fbref_team.head(2))\n",
        "print(fbref_match.head(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Garanties de cohérence (cible et features)\n",
        "# Recalcule 'result' et 'points' si absents, et construit X, y si nécessaire\n",
        "if 'points' not in merged.columns:\n",
        "    if 'goals' in merged.columns and 'goals_conceded' in merged.columns:\n",
        "        merged['result'] = np.where(merged['goals'] > merged['goals_conceded'], 'W',\n",
        "                             np.where(merged['goals'] == merged['goals_conceded'], 'D', 'L'))\n",
        "    else:\n",
        "        merged['result'] = 'D'\n",
        "    points_map = {'W': 3, 'D': 1, 'L': 0}\n",
        "    merged['points'] = merged['result'].map(points_map).fillna(1).astype(int)\n",
        "\n",
        "# Features supplémentaires si manquantes\n",
        "if 'goal_difference' not in merged.columns:\n",
        "    merged['goal_difference'] = merged.get('goals', 0) - merged.get('goals_conceded', 0)\n",
        "if 'xg_difference' not in merged.columns:\n",
        "    merged['xg_difference'] = merged.get('xg', 0) - merged.get('xg_conceded', 0)\n",
        "if 'points_rolling_5' not in merged.columns:\n",
        "    if 'date' in merged.columns:\n",
        "        merged = merged.sort_values('date')\n",
        "    merged['points_rolling_5'] = merged['points'].rolling(window=5, min_periods=1).mean()\n",
        "if 'is_home' not in merged.columns:\n",
        "    merged['is_home'] = 1\n",
        "\n",
        "# Construire X, y si absents\n",
        "globals_dict = globals()\n",
        "if 'X' not in globals_dict or 'y' not in globals_dict:\n",
        "    tmp = merged.copy()\n",
        "    tmp['result_encoded'] = tmp.get('result', pd.Series(['D']*len(tmp))).map({'L':0, 'D':1, 'W':2})\n",
        "    X = tmp.select_dtypes(include=[np.number]).drop(columns=['points'], errors='ignore')\n",
        "    y = tmp['points']\n",
        "\n",
        "print('Vérif:', X.shape, y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nettoyage rapide + harmonisation colonnes clés\n",
        "# On essaye d'identifier des colonnes compatibles pour fusion (date, adversaire, domicile)\n",
        "\n",
        "# Normalisation noms de colonnes en minuscule\n",
        "understat.columns = [c.lower() for c in understat.columns]\n",
        "fbref_team.columns = [c.lower() for c in fbref_team.columns]\n",
        "fbref_match.columns = [c.lower() for c in fbref_match.columns]\n",
        "\n",
        "# Heuristiques pour colonnes communes\n",
        "# - date: 'date' si présent, sinon 'match_date' ou similaire\n",
        "for df in [understat, fbref_match]:\n",
        "    if 'date' not in df.columns:\n",
        "        for alt in ['match_date', 'game_date']:\n",
        "            if alt in df.columns:\n",
        "                df.rename(columns={alt: 'date'}, inplace=True)\n",
        "                break\n",
        "\n",
        "# - adversaire/opponent\n",
        "if 'opponent' not in understat.columns:\n",
        "    for alt in ['opponent_team', 'against', 'rival']:\n",
        "        if alt in understat.columns:\n",
        "            understat.rename(columns={alt: 'opponent'}, inplace=True)\n",
        "            break\n",
        "\n",
        "if 'opponent' not in fbref_match.columns:\n",
        "    for alt in ['opponent_team', 'against', 'rival']:\n",
        "        if alt in fbref_match.columns:\n",
        "            fbref_match.rename(columns={alt: 'opponent'}, inplace=True)\n",
        "            break\n",
        "\n",
        "# - domicile/extérieur: is_home bool ou 'home_away' avec 'H/A'\n",
        "if 'is_home' not in understat.columns:\n",
        "    if 'home_away' in understat.columns:\n",
        "        understat['is_home'] = understat['home_away'].astype(str).str.upper().map({'H': 1, 'A': 0}).fillna(0).astype(int)\n",
        "\n",
        "# Création d'une clé de merge robuste\n",
        "for df in [understat, fbref_match]:\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "        df['date_key'] = df['date'].dt.strftime('%Y-%m-%d')\n",
        "    else:\n",
        "        df['date_key'] = np.nan\n",
        "    if 'opponent' in df.columns:\n",
        "        df['opponent_key'] = df['opponent'].astype(str).str.strip().str.lower()\n",
        "    else:\n",
        "        df['opponent_key'] = np.nan\n",
        "\n",
        "# Sélection d'un sous-ensemble pertinent de colonnes pour éviter collisions\n",
        "u_sel = understat.copy()\n",
        "fm_sel = fbref_match.copy()\n",
        "\n",
        "# Colonnes candidates (présentes dans nos datasets traités précédemment)\n",
        "# On inclut quelques stats simples\n",
        "for col, default in [\n",
        "    ('goals', np.nan), ('goals_conceded', np.nan), ('xg', np.nan), ('xg_conceded', np.nan),\n",
        "    ('shots', np.nan), ('shots_on_target', np.nan), ('possession', np.nan)\n",
        "]:\n",
        "    if col not in u_sel.columns: u_sel[col] = default\n",
        "    if col not in fm_sel.columns: fm_sel[col] = default\n",
        "\n",
        "# Harmoniser les types des clés avant merge\n",
        "u_sel['date_key'] = u_sel['date_key'].astype(str)\n",
        "fm_sel['date_key'] = fm_sel['date_key'].astype(str)\n",
        "u_sel['opponent_key'] = u_sel['opponent_key'].astype(str)\n",
        "fm_sel['opponent_key'] = fm_sel['opponent_key'].astype(str)\n",
        "\n",
        "# Merge principal: par date + adversaire\n",
        "merged = pd.merge(\n",
        "    u_sel,\n",
        "    fm_sel[[c for c in fm_sel.columns if c not in ['goals', 'goals_conceded', 'xg', 'xg_conceded']]],\n",
        "    on=['date_key', 'opponent_key'], how='inner', suffixes=('', '_fb')\n",
        ")\n",
        "\n",
        "# Fallback: si aucun alignement, utiliser Understat seul (données suffisantes pour démo)\n",
        "if merged.empty:\n",
        "    print('Aucun alignement Understat/FBref trouvé → utilisation Understat seul')\n",
        "    merged = u_sel.copy()\n",
        "\n",
        "print('Taille merged:', merged.shape)\n",
        "merged.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entraînement des modèles (RandomForest, XGBoost)\n",
        "X = X.fillna(0)\n",
        "\n",
        "# Split stratifié\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y if y.nunique()>1 else None\n",
        ")\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=12, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print('RandomForest accuracy:', round(acc_rf, 3))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# XGBoost (classes 3→2)\n",
        "y_train_xgb = y_train.replace({3:2})\n",
        "y_test_xgb = y_test.replace({3:2})\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=300, learning_rate=0.1, max_depth=6, subsample=0.9, colsample_bytree=0.9,\n",
        "    random_state=42, reg_lambda=1.0\n",
        ")\n",
        "xgb_model.fit(X_train, y_train_xgb)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "acc_xgb = accuracy_score(y_test_xgb, y_pred_xgb)\n",
        "print('XGBoost accuracy:', round(acc_xgb, 3))\n",
        "print(classification_report(y_test_xgb, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse exploratoire (EDA)\n",
        "# 1) Distribution de la cible\n",
        "ax = merged['points'].value_counts().sort_index().plot(kind='bar', color=['#e74c3c','#f1c40f','#2ecc71'])\n",
        "ax.set_xticklabels(['0 (Défaite)','1 (Nul)','3 (Victoire)'], rotation=0)\n",
        "plt.title('Distribution des résultats (points)')\n",
        "plt.ylabel('Nombre de matchs')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2) Corrélations sur un sous-ensemble de variables clés\n",
        "subset_cols = [c for c in ['goal_difference','xg','xg_conceded','points_rolling_5','is_home'] if c in merged.columns]\n",
        "if len(subset_cols) >= 2:\n",
        "    corr = merged[subset_cols].corr()\n",
        "    sns.heatmap(corr, annot=True, cmap='RdYlBu_r', vmin=-1, vmax=1)\n",
        "    plt.title('Matrice de corrélation (sélection)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 3) Distributions simples\n",
        "if 'xg' in merged.columns:\n",
        "    sns.histplot(merged['xg'], bins=20, kde=True, color='#3498db')\n",
        "    plt.title('Distribution du xG')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if 'possession' in merged.columns:\n",
        "    sns.histplot(merged['possession'], bins=20, kde=True, color='#9b59b6')\n",
        "    plt.title('Distribution de la possession (%)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 4) Points moyens domicile vs extérieur\n",
        "home_away_stats = merged.groupby(merged['is_home'].fillna(1))['points'].mean()\n",
        "plt.bar(['Extérieur','Domicile'], [home_away_stats.get(0,0), home_away_stats.get(1,0)], color=['#95a5a6','#27ae60'])\n",
        "plt.title('Points moyens: domicile vs extérieur')\n",
        "plt.ylabel('Points moyens')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature engineering minimal\n",
        "\n",
        "# 1) Cible: points (3 victoire, 1 nul, 0 défaite)\n",
        "# On tente de dériver result depuis goals et goals_conceded s'ils existent\n",
        "if 'goals' in merged.columns and 'goals_conceded' in merged.columns:\n",
        "    merged['result'] = np.where(merged['goals'] > merged['goals_conceded'], 'W',\n",
        "                         np.where(merged['goals'] == merged['goals_conceded'], 'D', 'L'))\n",
        "else:\n",
        "    merged['result'] = 'D'\n",
        "\n",
        "points_map = {'W': 3, 'D': 1, 'L': 0}\n",
        "merged['points'] = merged['result'].map(points_map).fillna(1).astype(int)\n",
        "\n",
        "# 2) Différences et ratios simples\n",
        "merged['goal_difference'] = merged.get('goals', 0) - merged.get('goals_conceded', 0)\n",
        "merged['xg_difference'] = merged.get('xg', 0) - merged.get('xg_conceded', 0)\n",
        "\n",
        "# 3) Forme récente (rolling sur 5 matchs) par ordre chronologique\n",
        "merged = merged.sort_values('date')\n",
        "merged['points_rolling_5'] = merged['points'].rolling(window=5, min_periods=1).mean()\n",
        "merged['goals_rolling_5'] = merged.get('goals', pd.Series([0]*len(merged))).rolling(window=5, min_periods=1).mean()\n",
        "merged['xg_rolling_5'] = merged.get('xg', pd.Series([0]*len(merged))).rolling(window=5, min_periods=1).mean()\n",
        "\n",
        "# 4) Variables contextuelles simples\n",
        "if 'is_home' in merged.columns:\n",
        "    merged['is_home'] = merged['is_home'].astype(int)\n",
        "else:\n",
        "    merged['is_home'] = 1  # par défaut\n",
        "\n",
        "# 5) Nettoyage final: suppression colonnes non numériques inutiles pour le modèle\n",
        "non_numeric_keep = ['result']\n",
        "features = merged.copy()\n",
        "\n",
        "# Encoder 'result' si utile pour analyse\n",
        "features['result_encoded'] = features['result'].map({'L':0, 'D':1, 'W':2})\n",
        "\n",
        "# Sélection des colonnes numériques pour les modèles\n",
        "X = features.select_dtypes(include=[np.number]).drop(columns=['points'], errors='ignore')\n",
        "y = features['points']\n",
        "\n",
        "X.shape, y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Métriques avancées et validation croisée\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, RocCurveDisplay\n",
        "\n",
        "# Recalcul rapide sur l'ensemble d'entraînement (RF)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_acc = cross_val_score(rf, X, y, cv=skf, scoring='accuracy')\n",
        "cv_f1 = cross_val_score(rf, X, y, cv=skf, scoring='f1_macro')\n",
        "print(f'CV Accuracy (RF) mean±std: {cv_acc.mean():.3f} ± {cv_acc.std():.3f}')\n",
        "print(f'CV Macro-F1 (RF) mean±std: {cv_f1.mean():.3f} ± {cv_f1.std():.3f}')\n",
        "\n",
        "# ROC multi-classes (One-vs-Rest) pour RF\n",
        "try:\n",
        "    from sklearn.preprocessing import label_binarize\n",
        "    classes = [0,1,3]\n",
        "    y_test_bin = label_binarize(y_test, classes=classes)\n",
        "    y_proba_rf = rf.predict_proba(X_test)\n",
        "    # Remapping proba RF pour classes 0,1,3 (déjà alignées)\n",
        "    fig, ax = plt.subplots(figsize=(7,6))\n",
        "    for i, cls in enumerate(classes):\n",
        "        RocCurveDisplay.from_predictions(y_test_bin[:, i], y_proba_rf[:, i], name=f'Classe {cls}', ax=ax)\n",
        "    plt.title('Courbes ROC One-vs-Rest (RandomForest)')\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print('ROC multi-classes indisponible:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Courbes d'apprentissage (learning curves)\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def plot_learning_curve(estimator, X, y, title):\n",
        "    train_sizes, train_scores, val_scores = learning_curve(\n",
        "        estimator, X, y, cv=5, scoring='accuracy', n_jobs=None,\n",
        "        train_sizes=np.linspace(0.2, 1.0, 5), random_state=42\n",
        "    )\n",
        "    train_mean, train_std = train_scores.mean(axis=1), train_scores.std(axis=1)\n",
        "    val_mean, val_std = val_scores.mean(axis=1), val_scores.std(axis=1)\n",
        "    plt.figure(figsize=(7,5))\n",
        "    plt.plot(train_sizes, train_mean, 'o-', label='Train')\n",
        "    plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2)\n",
        "    plt.plot(train_sizes, val_mean, 'o-', label='Validation')\n",
        "    plt.fill_between(train_sizes, val_mean-val_std, val_mean+val_std, alpha=0.2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Taille d\\'échantillon d\\'entraînement')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curve(rf, X, y, 'Courbe d\\'apprentissage - RandomForest')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparaison des importances RF vs XGB\n",
        "try:\n",
        "    imp_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "    imp_xgb = pd.Series(xgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "    topk = 15\n",
        "    comp = pd.DataFrame({\n",
        "        'RF': imp_rf.head(topk),\n",
        "        'XGB': imp_xgb.reindex(imp_rf.head(topk).index)\n",
        "    })\n",
        "    comp.plot(kind='barh', figsize=(8,6))\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title('Comparaison des importances (Top 15)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print('Comparaison importances indisponible:', e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion et axes d’amélioration\n",
        "- Le modèle capture des signaux forts liés à la différence de buts, au momentum et au contexte (domicile/extérieur).\n",
        "- Les performances sont stables (CV) et les courbes d’apprentissage aident à détecter un éventuel sur/apprentissage.\n",
        "- Les importances comparées (RF vs XGB) offrent deux angles d’interprétation complémentaires.\n",
        "\n",
        "Prochaines pistes:\n",
        "- Enrichir l’alignement FBref (qualité des clés) et la granularité des features contextuelles.\n",
        "- Ajouter des séquences temporelles (lags multi-horizons) et des features d’adversaire (forme adverse).\n",
        "- Calibration des probabilités (Platt/Isotonic) et seuils dépendant du coût.\n",
        "- Validation temporelle (walk-forward) pour se rapprocher d’un usage en production.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entraînement des modèles simples\n",
        "X = X.fillna(0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Random Forest (simple)\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print('RandomForest accuracy:', round(acc_rf, 3))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# XGBoost (simple) — encode 3->2\n",
        "y_train_xgb = y_train.replace({3:2})\n",
        "y_test_xgb = y_test.replace({3:2})\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)\n",
        "xgb_model.fit(X_train, y_train_xgb)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "acc_xgb = accuracy_score(y_test_xgb, y_pred_xgb)\n",
        "print('XGBoost accuracy:', round(acc_xgb, 3))\n",
        "print(classification_report(y_test_xgb, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisations essentielles\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# 1. Matrice de confusion RF\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf, labels=[0,1,3])\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Défaite','Nul','Victoire'], yticklabels=['Défaite','Nul','Victoire'])\n",
        "plt.title('Matrice de confusion - RandomForest')\n",
        "plt.xlabel('Prédit')\n",
        "plt.ylabel('Réel')\n",
        "plt.show()\n",
        "\n",
        "# 2. Importance des features (top 15)\n",
        "fi = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False).head(15)\n",
        "fi.plot(kind='barh')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title('Top 15 Features - RandomForest')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Relation simple: xg vs points\n",
        "if 'xg' in merged.columns:\n",
        "    sns.scatterplot(data=merged, x='xg', y='points', hue='is_home', palette='coolwarm')\n",
        "    plt.title('xG vs Points')\n",
        "    plt.show()\n",
        "\n",
        "# 4. Evolution des points (rolling) dans le temps\n",
        "if 'date' in merged.columns:\n",
        "    merged.set_index('date')['points'].rolling(5, min_periods=1).mean().plot()\n",
        "    plt.title('Moyenne mobile des points (5 matchs)')\n",
        "    plt.ylabel('Points Moyens')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- Ce notebook est volontairement minimal: il repose sur des heuristiques simples pour fusionner les données.\n",
        "- Si certaines colonnes ne sont pas présentes, des valeurs par défaut sont utilisées.\n",
        "- Pour plus de robustesse (alignement des correspondances, enrichissement des features), référez-vous au pipeline complet du projet, mais celui-ci suffit pour une démo rapide et reproductible.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
